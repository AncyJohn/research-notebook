{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mounting your drive in Colab\" means using a specific command or UI action to link your personal Google Drive cloud storage to the temporary virtual machine (runtime) running your Google Colab notebook. This allows your notebook's code to read from and write to your Drive files as if they were local files in the Colab environment."
      ],
      "metadata": {
        "id": "YioM-Hdvx35D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq-xZzV54Ekc",
        "outputId": "5db7fe52-afe6-46fd-81be-3a1e4982b9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Project exists. Forcing sync with GitHub. ---\n",
            "/content/drive/MyDrive/my_freelance_projects/research-notebook\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 7 (delta 5), reused 7 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (7/7), 997 bytes | 7.00 KiB/s, done.\n",
            "From https://github.com/AncyJohn/research-notebook\n",
            "   4d1f2ec..14bb703  main       -> origin/main\n",
            "HEAD is now at 14bb703 More modification\n",
            "Repository Force-Synced to latest GitHub version.\n",
            "Current Working Directory: /content/drive/MyDrive/my_freelance_projects/research-notebook\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define your project path and Git URL\n",
        "PROJECT_PATH = '/content/drive/MyDrive/my_freelance_projects'\n",
        "GIT_REPO_URL = 'https://github.com/AncyJohn/research-notebook.git'\n",
        "REPO_NAME = 'research-notebook'\n",
        "FULL_PATH = os.path.join(PROJECT_PATH, REPO_NAME)\n",
        "\n",
        "# 3. Check and Clone/Update\n",
        "if not os.path.exists(FULL_PATH):\n",
        "    os.makedirs(PROJECT_PATH, exist_ok=True)\n",
        "    %cd {PROJECT_PATH}\n",
        "    !git clone {GIT_REPO_URL}\n",
        "    print(f\"Successfully cloned into {FULL_PATH}\")\n",
        "else:\n",
        "    print(f\"--- Project exists. Forcing sync with GitHub. ---\")\n",
        "    %cd {FULL_PATH}\n",
        "\n",
        "    # 1. Fetch latest data from GitHub\n",
        "    !git fetch origin\n",
        "\n",
        "    # 2. FORCE the local Drive files to match GitHub exactly\n",
        "    # This kills the \"overwritten by merge\" error\n",
        "    !git reset --hard origin/main\n",
        "    # This deletes all untracked directories (-d) and files (-f)\n",
        "    #!git clean -fd\n",
        "\n",
        "    print(f\"Repository Force-Synced to latest GitHub version.\")\n",
        "\n",
        "print(f\"Current Working Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file\n",
        "from google.colab import files\n",
        "files.upload() # Select the 'kaggle.json' file you downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "uYf9JUSHvf3R",
        "outputId": "5ee650de-67fe-4e85-887d-8027fc39b311"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4b36ac9-f866-4712-b2f1-82ffbde303a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4b36ac9-f866-4712-b2f1-82ffbde303a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ancyjohn\",\"key\":\"4d2f0970f090251bb11dc160015cb9e9\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move it to the secret loacation\n",
        "!mkdir -p ~/.kaggle # Create the hidden directory\n",
        "!cp kaggle.json ~/.kaggle/ # Move the file there\n",
        "!chmod 600 ~/.kaggle/kaggle.json #Set permissions (required by Kaggle for security)"
      ],
      "metadata": {
        "id": "tcDkxPRjv6Vv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!kaggle competitions download -c titanic\n",
        "!unzip -o titanic.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsytrSxkwW0M",
        "outputId": "17115a69-e2c3-4780-aac6-8f84d471877f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading titanic.zip to /content/drive/MyDrive/my_freelance_projects/research-notebook\n",
            "\r  0% 0.00/34.1k [00:00<?, ?B/s]\n",
            "\r100% 34.1k/34.1k [00:00<00:00, 3.17MB/s]\n",
            "Archive:  titanic.zip\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to the folder containing your .py files\n",
        "%cd \"phase3/pipelines/titanic/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54gK7dXT6awH",
        "outputId": "ea3a7c6f-393d-4afb-fadb-7c31c7b59498"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../../../train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uf4MGCVKnxU",
        "outputId": "e401df05-7534-4026-d293-b29fb098a6fb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../../../train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Train the model\n",
        "!python train.py\n",
        "\n",
        "# Step 2: Evaluate the best saved weights\n",
        "!python evaluate.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsDcs1Z58SPC",
        "outputId": "9f015df1-0189-4169-d214-355bc32ed7aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from: ../../../train.csv\n",
            "üíæ Saving stats to artifacts/models/train_stats.joblib...\n",
            "üöÄ Starting training on cpu...\n",
            "‚úÖ Validation loss decreased (None --> 0.7226). Saving model...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic/train.py\", line 248, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic/train.py\", line 226, in main\n",
            "    early_stopper(epoch_v, model)\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic/train.py\", line 130, in __call__\n",
            "    torch.save(model.state_dict(), \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 828, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)  # type: ignore[arg-type]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 792, in __init__\n",
            "    torch._C.PyTorchFileWriter(\n",
            "RuntimeError: Parent directory phase3/pipelines/titanic/artifacts/models does not exist.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic/evaluate.py\", line 94, in <module>\n",
            "    evaluate()\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/phase3/pipelines/titanic/evaluate.py\", line 55, in evaluate\n",
            "    model.load_state_dict(torch.load(config['outputs']['model_path'], weights_only=True, map_location=device))\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/models/mlp.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIMYu8P6ITrj",
        "outputId": "ff2931b3-9acd-46f2-ec8d-9702029eda5a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from: ../../../train.csv\n",
            "üíæ Saving stats to artifacts/models/train_stats.joblib...\n",
            "2026-02-10 03:29:21,441 - INFO - üöÄ Starting training on cpu...\n",
            "2026-02-10 03:29:21,460 - INFO - ‚úÖ Validation loss decreased (None --> 0.7226). Saving model...\n",
            "2026-02-10 03:29:21,474 - INFO - Epoch 01: Train Loss 0.7253 | Val Loss 0.7226\n",
            "2026-02-10 03:29:21,490 - INFO - ‚úÖ Validation loss decreased (0.7226043939590454 --> 0.7205). Saving model...\n",
            "2026-02-10 03:29:21,500 - INFO - Epoch 02: Train Loss 0.7221 | Val Loss 0.7205\n",
            "2026-02-10 03:29:21,520 - INFO - ‚úÖ Validation loss decreased (0.7205283045768738 --> 0.7181). Saving model...\n",
            "2026-02-10 03:29:21,533 - INFO - Epoch 03: Train Loss 0.7176 | Val Loss 0.7181\n",
            "2026-02-10 03:29:21,551 - INFO - ‚úÖ Validation loss decreased (0.7180638909339905 --> 0.7153). Saving model...\n",
            "2026-02-10 03:29:21,561 - INFO - Epoch 04: Train Loss 0.7136 | Val Loss 0.7153\n",
            "2026-02-10 03:29:21,576 - INFO - ‚úÖ Validation loss decreased (0.7152968049049377 --> 0.7123). Saving model...\n",
            "2026-02-10 03:29:21,587 - INFO - Epoch 05: Train Loss 0.7105 | Val Loss 0.7123\n",
            "2026-02-10 03:29:21,602 - INFO - ‚úÖ Validation loss decreased (0.7122586369514465 --> 0.7091). Saving model...\n",
            "2026-02-10 03:29:21,612 - INFO - Epoch 06: Train Loss 0.7072 | Val Loss 0.7091\n",
            "2026-02-10 03:29:21,629 - INFO - ‚úÖ Validation loss decreased (0.7091209292411804 --> 0.7058). Saving model...\n",
            "2026-02-10 03:29:21,638 - INFO - Epoch 07: Train Loss 0.7041 | Val Loss 0.7058\n",
            "2026-02-10 03:29:21,652 - INFO - ‚úÖ Validation loss decreased (0.7057745456695557 --> 0.7023). Saving model...\n",
            "2026-02-10 03:29:21,661 - INFO - Epoch 08: Train Loss 0.7014 | Val Loss 0.7023\n",
            "2026-02-10 03:29:21,677 - INFO - ‚úÖ Validation loss decreased (0.7023130655288696 --> 0.6988). Saving model...\n",
            "2026-02-10 03:29:21,687 - INFO - Epoch 09: Train Loss 0.6996 | Val Loss 0.6988\n",
            "2026-02-10 03:29:21,701 - INFO - ‚úÖ Validation loss decreased (0.6987560391426086 --> 0.6950). Saving model...\n",
            "2026-02-10 03:29:21,713 - INFO - Epoch 10: Train Loss 0.6934 | Val Loss 0.6950\n",
            "2026-02-10 03:29:21,727 - INFO - ‚úÖ Validation loss decreased (0.6950360536575317 --> 0.6910). Saving model...\n",
            "2026-02-10 03:29:21,736 - INFO - Epoch 11: Train Loss 0.6905 | Val Loss 0.6910\n",
            "2026-02-10 03:29:21,750 - INFO - ‚úÖ Validation loss decreased (0.6909995675086975 --> 0.6868). Saving model...\n",
            "2026-02-10 03:29:21,760 - INFO - Epoch 12: Train Loss 0.6882 | Val Loss 0.6868\n",
            "2026-02-10 03:29:21,776 - INFO - ‚úÖ Validation loss decreased (0.6867908239364624 --> 0.6823). Saving model...\n",
            "2026-02-10 03:29:21,786 - INFO - Epoch 13: Train Loss 0.6825 | Val Loss 0.6823\n",
            "2026-02-10 03:29:21,802 - INFO - ‚úÖ Validation loss decreased (0.6823051571846008 --> 0.6774). Saving model...\n",
            "2026-02-10 03:29:21,812 - INFO - Epoch 14: Train Loss 0.6773 | Val Loss 0.6774\n",
            "2026-02-10 03:29:21,826 - INFO - ‚úÖ Validation loss decreased (0.677436888217926 --> 0.6723). Saving model...\n",
            "2026-02-10 03:29:21,836 - INFO - Epoch 15: Train Loss 0.6733 | Val Loss 0.6723\n",
            "2026-02-10 03:29:21,852 - INFO - ‚úÖ Validation loss decreased (0.6722904443740845 --> 0.6661). Saving model...\n",
            "2026-02-10 03:29:21,862 - INFO - Epoch 16: Train Loss 0.6646 | Val Loss 0.6661\n",
            "2026-02-10 03:29:21,879 - INFO - ‚úÖ Validation loss decreased (0.6660957336425781 --> 0.6595). Saving model...\n",
            "2026-02-10 03:29:21,889 - INFO - Epoch 17: Train Loss 0.6623 | Val Loss 0.6595\n",
            "2026-02-10 03:29:21,906 - INFO - ‚úÖ Validation loss decreased (0.6595185995101929 --> 0.6524). Saving model...\n",
            "2026-02-10 03:29:21,929 - INFO - Epoch 18: Train Loss 0.6573 | Val Loss 0.6524\n",
            "2026-02-10 03:29:21,944 - INFO - ‚úÖ Validation loss decreased (0.6524445414543152 --> 0.6450). Saving model...\n",
            "2026-02-10 03:29:21,956 - INFO - Epoch 19: Train Loss 0.6485 | Val Loss 0.6450\n",
            "2026-02-10 03:29:21,971 - INFO - ‚úÖ Validation loss decreased (0.6449735164642334 --> 0.6370). Saving model...\n",
            "2026-02-10 03:29:21,984 - INFO - Epoch 20: Train Loss 0.6418 | Val Loss 0.6370\n",
            "2026-02-10 03:29:21,998 - INFO - ‚úÖ Validation loss decreased (0.636975109577179 --> 0.6287). Saving model...\n",
            "2026-02-10 03:29:22,009 - INFO - Epoch 21: Train Loss 0.6344 | Val Loss 0.6287\n",
            "2026-02-10 03:29:22,027 - INFO - ‚úÖ Validation loss decreased (0.6286793947219849 --> 0.6206). Saving model...\n",
            "2026-02-10 03:29:22,038 - INFO - Epoch 22: Train Loss 0.6264 | Val Loss 0.6206\n",
            "2026-02-10 03:29:22,053 - INFO - ‚úÖ Validation loss decreased (0.6205561757087708 --> 0.6125). Saving model...\n",
            "2026-02-10 03:29:22,065 - INFO - Epoch 23: Train Loss 0.6191 | Val Loss 0.6125\n",
            "2026-02-10 03:29:22,081 - INFO - ‚úÖ Validation loss decreased (0.6124696135520935 --> 0.6044). Saving model...\n",
            "2026-02-10 03:29:22,092 - INFO - Epoch 24: Train Loss 0.6080 | Val Loss 0.6044\n",
            "2026-02-10 03:29:22,106 - INFO - ‚úÖ Validation loss decreased (0.6044099926948547 --> 0.5965). Saving model...\n",
            "2026-02-10 03:29:22,115 - INFO - Epoch 25: Train Loss 0.6005 | Val Loss 0.5965\n",
            "2026-02-10 03:29:22,130 - INFO - ‚úÖ Validation loss decreased (0.5965339541435242 --> 0.5888). Saving model...\n",
            "2026-02-10 03:29:22,139 - INFO - Epoch 26: Train Loss 0.5938 | Val Loss 0.5888\n",
            "2026-02-10 03:29:22,153 - INFO - ‚úÖ Validation loss decreased (0.5887956023216248 --> 0.5815). Saving model...\n",
            "2026-02-10 03:29:22,163 - INFO - Epoch 27: Train Loss 0.5844 | Val Loss 0.5815\n",
            "2026-02-10 03:29:22,178 - INFO - ‚úÖ Validation loss decreased (0.5814724564552307 --> 0.5741). Saving model...\n",
            "2026-02-10 03:29:22,188 - INFO - Epoch 28: Train Loss 0.5760 | Val Loss 0.5741\n",
            "2026-02-10 03:29:22,203 - INFO - ‚úÖ Validation loss decreased (0.5741145610809326 --> 0.5669). Saving model...\n",
            "2026-02-10 03:29:22,212 - INFO - Epoch 29: Train Loss 0.5683 | Val Loss 0.5669\n",
            "2026-02-10 03:29:22,226 - INFO - ‚úÖ Validation loss decreased (0.5668532848358154 --> 0.5602). Saving model...\n",
            "2026-02-10 03:29:22,237 - INFO - Epoch 30: Train Loss 0.5630 | Val Loss 0.5602\n",
            "2026-02-10 03:29:22,251 - INFO - ‚úÖ Validation loss decreased (0.5601675510406494 --> 0.5536). Saving model...\n",
            "2026-02-10 03:29:22,260 - INFO - Epoch 31: Train Loss 0.5516 | Val Loss 0.5536\n",
            "2026-02-10 03:29:22,276 - INFO - ‚úÖ Validation loss decreased (0.5536375045776367 --> 0.5473). Saving model...\n",
            "2026-02-10 03:29:22,286 - INFO - Epoch 32: Train Loss 0.5450 | Val Loss 0.5473\n",
            "2026-02-10 03:29:22,301 - INFO - ‚úÖ Validation loss decreased (0.5472719669342041 --> 0.5413). Saving model...\n",
            "2026-02-10 03:29:22,326 - INFO - Epoch 33: Train Loss 0.5370 | Val Loss 0.5413\n",
            "2026-02-10 03:29:22,340 - INFO - ‚úÖ Validation loss decreased (0.5412824749946594 --> 0.5353). Saving model...\n",
            "2026-02-10 03:29:22,350 - INFO - Epoch 34: Train Loss 0.5241 | Val Loss 0.5353\n",
            "2026-02-10 03:29:22,364 - INFO - ‚úÖ Validation loss decreased (0.5353099703788757 --> 0.5296). Saving model...\n",
            "2026-02-10 03:29:22,378 - INFO - Epoch 35: Train Loss 0.5258 | Val Loss 0.5296\n",
            "2026-02-10 03:29:22,402 - INFO - ‚úÖ Validation loss decreased (0.5296427607536316 --> 0.5244). Saving model...\n",
            "2026-02-10 03:29:22,416 - INFO - Epoch 36: Train Loss 0.5180 | Val Loss 0.5244\n",
            "2026-02-10 03:29:22,431 - INFO - ‚úÖ Validation loss decreased (0.5244424343109131 --> 0.5195). Saving model...\n",
            "2026-02-10 03:29:22,442 - INFO - Epoch 37: Train Loss 0.5133 | Val Loss 0.5195\n",
            "2026-02-10 03:29:22,461 - INFO - ‚úÖ Validation loss decreased (0.5194801092147827 --> 0.5147). Saving model...\n",
            "2026-02-10 03:29:22,475 - INFO - Epoch 38: Train Loss 0.5045 | Val Loss 0.5147\n",
            "2026-02-10 03:29:22,490 - INFO - ‚úÖ Validation loss decreased (0.5146637558937073 --> 0.5100). Saving model...\n",
            "2026-02-10 03:29:22,500 - INFO - Epoch 39: Train Loss 0.5003 | Val Loss 0.5100\n",
            "2026-02-10 03:29:22,515 - INFO - ‚úÖ Validation loss decreased (0.5100240707397461 --> 0.5057). Saving model...\n",
            "2026-02-10 03:29:22,526 - INFO - Epoch 40: Train Loss 0.4929 | Val Loss 0.5057\n",
            "2026-02-10 03:29:22,540 - INFO - ‚úÖ Validation loss decreased (0.5056872367858887 --> 0.5014). Saving model...\n",
            "2026-02-10 03:29:22,550 - INFO - Epoch 41: Train Loss 0.4934 | Val Loss 0.5014\n",
            "2026-02-10 03:29:22,565 - INFO - ‚úÖ Validation loss decreased (0.5014155507087708 --> 0.4974). Saving model...\n",
            "2026-02-10 03:29:22,576 - INFO - Epoch 42: Train Loss 0.4851 | Val Loss 0.4974\n",
            "2026-02-10 03:29:22,592 - INFO - ‚úÖ Validation loss decreased (0.4973752200603485 --> 0.4936). Saving model...\n",
            "2026-02-10 03:29:22,601 - INFO - Epoch 43: Train Loss 0.4804 | Val Loss 0.4936\n",
            "2026-02-10 03:29:22,616 - INFO - ‚úÖ Validation loss decreased (0.49357300996780396 --> 0.4900). Saving model...\n",
            "2026-02-10 03:29:22,626 - INFO - Epoch 44: Train Loss 0.4791 | Val Loss 0.4900\n",
            "2026-02-10 03:29:22,642 - INFO - ‚úÖ Validation loss decreased (0.4899868965148926 --> 0.4865). Saving model...\n",
            "2026-02-10 03:29:22,653 - INFO - Epoch 45: Train Loss 0.4712 | Val Loss 0.4865\n",
            "2026-02-10 03:29:22,672 - INFO - ‚úÖ Validation loss decreased (0.4865105450153351 --> 0.4832). Saving model...\n",
            "2026-02-10 03:29:22,684 - INFO - Epoch 46: Train Loss 0.4681 | Val Loss 0.4832\n",
            "2026-02-10 03:29:22,699 - INFO - ‚úÖ Validation loss decreased (0.4832362234592438 --> 0.4801). Saving model...\n",
            "2026-02-10 03:29:22,709 - INFO - Epoch 47: Train Loss 0.4652 | Val Loss 0.4801\n",
            "2026-02-10 03:29:22,723 - INFO - ‚úÖ Validation loss decreased (0.4800814688205719 --> 0.4770). Saving model...\n",
            "2026-02-10 03:29:22,750 - INFO - Epoch 48: Train Loss 0.4596 | Val Loss 0.4770\n",
            "2026-02-10 03:29:22,764 - INFO - ‚úÖ Validation loss decreased (0.4770281910896301 --> 0.4743). Saving model...\n",
            "2026-02-10 03:29:22,774 - INFO - Epoch 49: Train Loss 0.4601 | Val Loss 0.4743\n",
            "2026-02-10 03:29:22,790 - INFO - ‚úÖ Validation loss decreased (0.4742802381515503 --> 0.4717). Saving model...\n",
            "2026-02-10 03:29:22,801 - INFO - Epoch 50: Train Loss 0.4541 | Val Loss 0.4717\n",
            "2026-02-10 03:29:22,816 - INFO - ‚úÖ Validation loss decreased (0.4717056155204773 --> 0.4692). Saving model...\n",
            "2026-02-10 03:29:22,825 - INFO - Epoch 51: Train Loss 0.4496 | Val Loss 0.4692\n",
            "2026-02-10 03:29:22,840 - INFO - ‚úÖ Validation loss decreased (0.46923622488975525 --> 0.4668). Saving model...\n",
            "2026-02-10 03:29:22,849 - INFO - Epoch 52: Train Loss 0.4496 | Val Loss 0.4668\n",
            "2026-02-10 03:29:22,863 - INFO - ‚úÖ Validation loss decreased (0.46684712171554565 --> 0.4646). Saving model...\n",
            "2026-02-10 03:29:22,872 - INFO - Epoch 53: Train Loss 0.4473 | Val Loss 0.4646\n",
            "2026-02-10 03:29:22,891 - INFO - ‚úÖ Validation loss decreased (0.4646308422088623 --> 0.4626). Saving model...\n",
            "2026-02-10 03:29:22,902 - INFO - Epoch 54: Train Loss 0.4515 | Val Loss 0.4626\n",
            "2026-02-10 03:29:22,917 - INFO - ‚úÖ Validation loss decreased (0.4626106023788452 --> 0.4610). Saving model...\n",
            "2026-02-10 03:29:22,927 - INFO - Epoch 55: Train Loss 0.4504 | Val Loss 0.4610\n",
            "2026-02-10 03:29:22,942 - INFO - ‚úÖ Validation loss decreased (0.4609861671924591 --> 0.4592). Saving model...\n",
            "2026-02-10 03:29:22,952 - INFO - Epoch 56: Train Loss 0.4406 | Val Loss 0.4592\n",
            "2026-02-10 03:29:22,967 - INFO - ‚úÖ Validation loss decreased (0.45917633175849915 --> 0.4574). Saving model...\n",
            "2026-02-10 03:29:22,978 - INFO - Epoch 57: Train Loss 0.4465 | Val Loss 0.4574\n",
            "2026-02-10 03:29:22,996 - INFO - ‚úÖ Validation loss decreased (0.45736294984817505 --> 0.4557). Saving model...\n",
            "2026-02-10 03:29:23,009 - INFO - Epoch 58: Train Loss 0.4394 | Val Loss 0.4557\n",
            "2026-02-10 03:29:23,029 - INFO - ‚úÖ Validation loss decreased (0.45571890473365784 --> 0.4541). Saving model...\n",
            "2026-02-10 03:29:23,042 - INFO - Epoch 59: Train Loss 0.4403 | Val Loss 0.4541\n",
            "2026-02-10 03:29:23,057 - INFO - ‚úÖ Validation loss decreased (0.4541400074958801 --> 0.4527). Saving model...\n",
            "2026-02-10 03:29:23,067 - INFO - Epoch 60: Train Loss 0.4359 | Val Loss 0.4527\n",
            "2026-02-10 03:29:23,082 - INFO - ‚úÖ Validation loss decreased (0.4526616930961609 --> 0.4511). Saving model...\n",
            "2026-02-10 03:29:23,093 - INFO - Epoch 61: Train Loss 0.4350 | Val Loss 0.4511\n",
            "2026-02-10 03:29:23,109 - INFO - ‚úÖ Validation loss decreased (0.4511049687862396 --> 0.4500). Saving model...\n",
            "2026-02-10 03:29:23,119 - INFO - Epoch 62: Train Loss 0.4356 | Val Loss 0.4500\n",
            "2026-02-10 03:29:23,134 - INFO - ‚úÖ Validation loss decreased (0.44997474551200867 --> 0.4488). Saving model...\n",
            "2026-02-10 03:29:23,159 - INFO - Epoch 63: Train Loss 0.4325 | Val Loss 0.4488\n",
            "2026-02-10 03:29:23,174 - INFO - ‚úÖ Validation loss decreased (0.44882717728614807 --> 0.4477). Saving model...\n",
            "2026-02-10 03:29:23,184 - INFO - Epoch 64: Train Loss 0.4311 | Val Loss 0.4477\n",
            "2026-02-10 03:29:23,200 - INFO - ‚úÖ Validation loss decreased (0.44768938422203064 --> 0.4468). Saving model...\n",
            "2026-02-10 03:29:23,211 - INFO - Epoch 65: Train Loss 0.4259 | Val Loss 0.4468\n",
            "2026-02-10 03:29:23,229 - INFO - ‚úÖ Validation loss decreased (0.4468030035495758 --> 0.4460). Saving model...\n",
            "2026-02-10 03:29:23,241 - INFO - Epoch 66: Train Loss 0.4249 | Val Loss 0.4460\n",
            "2026-02-10 03:29:23,256 - INFO - ‚úÖ Validation loss decreased (0.44598662853240967 --> 0.4452). Saving model...\n",
            "2026-02-10 03:29:23,267 - INFO - Epoch 67: Train Loss 0.4319 | Val Loss 0.4452\n",
            "2026-02-10 03:29:23,283 - INFO - ‚úÖ Validation loss decreased (0.4452035427093506 --> 0.4445). Saving model...\n",
            "2026-02-10 03:29:23,296 - INFO - Epoch 68: Train Loss 0.4170 | Val Loss 0.4445\n",
            "2026-02-10 03:29:23,311 - INFO - ‚úÖ Validation loss decreased (0.44449228048324585 --> 0.4442). Saving model...\n",
            "2026-02-10 03:29:23,321 - INFO - Epoch 69: Train Loss 0.4295 | Val Loss 0.4442\n",
            "2026-02-10 03:29:23,336 - INFO - ‚úÖ Validation loss decreased (0.4441523551940918 --> 0.4436). Saving model...\n",
            "2026-02-10 03:29:23,346 - INFO - Epoch 70: Train Loss 0.4261 | Val Loss 0.4436\n",
            "2026-02-10 03:29:23,360 - INFO - ‚úÖ Validation loss decreased (0.4435885548591614 --> 0.4432). Saving model...\n",
            "2026-02-10 03:29:23,370 - INFO - Epoch 71: Train Loss 0.4245 | Val Loss 0.4432\n",
            "2026-02-10 03:29:23,384 - INFO - ‚úÖ Validation loss decreased (0.44317737221717834 --> 0.4424). Saving model...\n",
            "2026-02-10 03:29:23,394 - INFO - Epoch 72: Train Loss 0.4369 | Val Loss 0.4424\n",
            "2026-02-10 03:29:23,409 - INFO - ‚úÖ Validation loss decreased (0.4424148499965668 --> 0.4417). Saving model...\n",
            "2026-02-10 03:29:23,424 - INFO - Epoch 73: Train Loss 0.4186 | Val Loss 0.4417\n",
            "2026-02-10 03:29:23,450 - INFO - ‚úÖ Validation loss decreased (0.4416728615760803 --> 0.4412). Saving model...\n",
            "2026-02-10 03:29:23,460 - INFO - Epoch 74: Train Loss 0.4155 | Val Loss 0.4412\n",
            "2026-02-10 03:29:23,475 - INFO - ‚úÖ Validation loss decreased (0.44122281670570374 --> 0.4409). Saving model...\n",
            "2026-02-10 03:29:23,484 - INFO - Epoch 75: Train Loss 0.4173 | Val Loss 0.4409\n",
            "2026-02-10 03:29:23,501 - INFO - ‚úÖ Validation loss decreased (0.44091400504112244 --> 0.4407). Saving model...\n",
            "2026-02-10 03:29:23,511 - INFO - Epoch 76: Train Loss 0.4112 | Val Loss 0.4407\n",
            "2026-02-10 03:29:23,526 - INFO - ‚úÖ Validation loss decreased (0.4407009482383728 --> 0.4407). Saving model...\n",
            "2026-02-10 03:29:23,535 - INFO - Epoch 77: Train Loss 0.4141 | Val Loss 0.4407\n",
            "2026-02-10 03:29:23,549 - INFO - ‚úÖ Validation loss decreased (0.4406850337982178 --> 0.4404). Saving model...\n",
            "2026-02-10 03:29:23,571 - INFO - Epoch 78: Train Loss 0.4214 | Val Loss 0.4404\n",
            "2026-02-10 03:29:23,587 - INFO - ‚úÖ Validation loss decreased (0.4404086172580719 --> 0.4400). Saving model...\n",
            "2026-02-10 03:29:23,597 - INFO - Epoch 79: Train Loss 0.4162 | Val Loss 0.4400\n",
            "2026-02-10 03:29:23,611 - INFO - ‚úÖ Validation loss decreased (0.4399715065956116 --> 0.4397). Saving model...\n",
            "2026-02-10 03:29:23,621 - INFO - Epoch 80: Train Loss 0.4255 | Val Loss 0.4397\n",
            "2026-02-10 03:29:23,637 - INFO - ‚úÖ Validation loss decreased (0.4396818280220032 --> 0.4392). Saving model...\n",
            "2026-02-10 03:29:23,647 - INFO - Epoch 81: Train Loss 0.4128 | Val Loss 0.4392\n",
            "2026-02-10 03:29:23,661 - INFO - ‚úÖ Validation loss decreased (0.4392227530479431 --> 0.4392). Saving model...\n",
            "2026-02-10 03:29:23,672 - INFO - Epoch 82: Train Loss 0.4148 | Val Loss 0.4392\n",
            "2026-02-10 03:29:23,691 - INFO - ‚úÖ Validation loss decreased (0.4392032325267792 --> 0.4392). Saving model...\n",
            "2026-02-10 03:29:23,704 - INFO - Epoch 83: Train Loss 0.4138 | Val Loss 0.4392\n",
            "2026-02-10 03:29:23,718 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 1/10\n",
            "2026-02-10 03:29:23,719 - INFO - Epoch 84: Train Loss 0.4195 | Val Loss 0.4392\n",
            "2026-02-10 03:29:23,731 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 2/10\n",
            "2026-02-10 03:29:23,731 - INFO - Epoch 85: Train Loss 0.4166 | Val Loss 0.4394\n",
            "2026-02-10 03:29:23,744 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 3/10\n",
            "2026-02-10 03:29:23,744 - INFO - Epoch 86: Train Loss 0.4082 | Val Loss 0.4392\n",
            "2026-02-10 03:29:23,756 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 4/10\n",
            "2026-02-10 03:29:23,757 - INFO - Epoch 87: Train Loss 0.4057 | Val Loss 0.4393\n",
            "2026-02-10 03:29:23,768 - INFO - ‚úÖ Validation loss decreased (0.43917182087898254 --> 0.4390). Saving model...\n",
            "2026-02-10 03:29:23,779 - INFO - Epoch 88: Train Loss 0.4158 | Val Loss 0.4390\n",
            "2026-02-10 03:29:23,794 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 1/10\n",
            "2026-02-10 03:29:23,794 - INFO - Epoch 89: Train Loss 0.4213 | Val Loss 0.4390\n",
            "2026-02-10 03:29:23,810 - INFO - ‚úÖ Validation loss decreased (0.43903055787086487 --> 0.4389). Saving model...\n",
            "2026-02-10 03:29:23,821 - INFO - Epoch 90: Train Loss 0.4200 | Val Loss 0.4389\n",
            "2026-02-10 03:29:23,835 - INFO - ‚úÖ Validation loss decreased (0.4389294683933258 --> 0.4388). Saving model...\n",
            "2026-02-10 03:29:23,847 - INFO - Epoch 91: Train Loss 0.3994 | Val Loss 0.4388\n",
            "2026-02-10 03:29:23,862 - INFO - ‚úÖ Validation loss decreased (0.4387955963611603 --> 0.4387). Saving model...\n",
            "2026-02-10 03:29:23,876 - INFO - Epoch 92: Train Loss 0.4159 | Val Loss 0.4387\n",
            "2026-02-10 03:29:23,892 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 1/10\n",
            "2026-02-10 03:29:23,892 - INFO - Epoch 93: Train Loss 0.4157 | Val Loss 0.4389\n",
            "2026-02-10 03:29:23,905 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 2/10\n",
            "2026-02-10 03:29:23,905 - INFO - Epoch 94: Train Loss 0.4146 | Val Loss 0.4394\n",
            "2026-02-10 03:29:23,918 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 3/10\n",
            "2026-02-10 03:29:23,919 - INFO - Epoch 95: Train Loss 0.4089 | Val Loss 0.4398\n",
            "2026-02-10 03:29:23,932 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 4/10\n",
            "2026-02-10 03:29:23,932 - INFO - Epoch 96: Train Loss 0.4126 | Val Loss 0.4401\n",
            "2026-02-10 03:29:23,944 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 5/10\n",
            "2026-02-10 03:29:23,945 - INFO - Epoch 97: Train Loss 0.4177 | Val Loss 0.4399\n",
            "2026-02-10 03:29:23,960 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 6/10\n",
            "2026-02-10 03:29:23,961 - INFO - Epoch 98: Train Loss 0.4061 | Val Loss 0.4398\n",
            "2026-02-10 03:29:23,973 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 7/10\n",
            "2026-02-10 03:29:23,974 - INFO - Epoch 99: Train Loss 0.4114 | Val Loss 0.4397\n",
            "2026-02-10 03:29:23,986 - INFO - ‚ö†Ô∏è No improvement. EarlyStopping counter: 8/10\n",
            "2026-02-10 03:29:23,987 - INFO - Epoch 100: Train Loss 0.4097 | Val Loss 0.4395\n",
            "üìä Plot saved to artifacts/plots/loss_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vcxUs7RZL8y",
        "outputId": "579aff6a-c3a5-4a89-de69-48c31bf48a71"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation complete. Metrics saved to artifacts/metrics/metrics.json\n",
            "Accuracy: 0.8045 | Loss: 0.4387\n"
          ]
        }
      ]
    }
  ]
}