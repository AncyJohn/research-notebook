# Path C: My Learnings

**1. `import os` (The Operating System)**

In a notebook, you usually know exactly where your files are. In a script, your code needs to be "environment aware."

- **Path Management:** It allows the script to find data files regardless of whether it’s running on your Windows laptop, a Mac, or a Linux server in the cloud.
- **Reproducibility:** You used it in `set_reproducibility` to set `os.environ['PYTHONHASHSEED']`. This is vital because Python's built-in dictionaries and hashes can be "randomised" every time you restart. Forcing a seed here ensures that your data is processed in the **exact same way** every run.
- **Hardware Control:** It allows you to set environment variables for your GPU (like the `CUBLAS_WORKSPACE_CONFIG` we used for deterministic algorithms).

**2. `import yaml` (The Configuration)**

YAML (Yet Another Markup Language) is the "remote control" for your code.

- **Hardcoding vs. Configuration:** Instead of searching through 200 lines of code to change a `learning_rate`, you change one line in `config.yaml`.
- **Experiment Tracking:** When you eventually run 50 different versions of your model, you can save a copy of the `config.yaml` alongside each model. This tells you exactly what settings produced that specific result months later.
- **Human Readable:** Unlike JSON or XML, YAML is very easy for humans to read and edit without accidentally breaking the syntax.

**3. `import joblib` (The "Object Freezer")**

While PyTorch has its own way to save models (`.pt` files), it isn't great at saving standard Python objects like Dictionaries or Scalers.

- **Saving Metadata:** Your `PreprocessingDataset` calculates the **mean** and **standard deviation** of the training data. If you don't use those exact same numbers on the test data, your model will get "confused" and give wrong predictions.
- **Persistence:** `joblib.dump(train_stats, ...)` "freezes" those numbers into a file. `evaluate.py` then "thaws" them out.
- **Efficiency:** `joblib` is much faster and more memory-efficient than the standard Python `pickle` library, especially when dealing with large NumPy arrays or complex dictionaries containing tensors.

---

**Summary Table**

| **Library** | **Role** | **Notebook Equivalent** |
| --- | --- | --- |
| **os** | Handles paths and hardware settings | Hardcoded strings (e.g., `"/path/to/data"`) |
| **yaml** | Separates "Settings" from "Logic" | Variables at the top of a cell (e.g., `LR = 0.01`) |
| **joblib** | Saves/Loads non-model data (stats) | Just keeping variables in the notebook's memor |

In a professional data science pipeline, the generated files are the **artifacts** of your experiment. They represent the "frozen" state of your work so it can be reproduced or deployed without retraining.

**1. `best_model.pt` (The Brain)**

- **What it is:** A PyTorch "State Dictionary" file.
- **Purpose:** It contains the final, optimized weights and biases of your neural network. Your `EarlyStopping` class saved this specific file because it represents the moment your model had the lowest error during training.
- **Usage:** You load this in `evaluate.py` or `predict.py` to make actual predictions.

**2. `train_stats.joblib` (The Translator)**

- **What it is:** A serialized Python object saved using the [**Joblib library**](https://joblib.readthedocs.io/en/latest/persistence.html).
- **Purpose:** It stores the **means, standard deviations, and categorical mappings** from your training data.
- **Usage:** This is critical for preventing **data leakage**. When you have new "unseen" data, you must transform it using these exact training stats; otherwise, the model will receive data it doesn't recognize.

**3. `loss_curve.png` (The Health Chart)**

- **What it is:** A standard image file generated by Matplotlib.
- **Purpose:** It visualizes the training vs. validation loss over time.
- **Usage:** It’s a diagnostic tool. If the training loss keeps going down but the validation loss starts going up, you can see exactly where the model started **overfitting**.

**4. `test_file.pt` (The Verification)**

- **What it is:** A temporary PyTorch file.
- **Purpose:** We created this manually in the notebook to verify that your script had **permission** to write to Google Drive.
- **Usage:** It is not needed for the model; you can safely delete it now that you know your paths are working.

**Summary of Artifacts**

| **File** | **Role** | **Importance** |
| --- | --- | --- |
| **`.pt`** | Saved Model | Primary goal of the project. |
| **`.joblib`** | Preprocessing Data | Essential for consistent predictions. |
| **`.png`** | Performance Visual | Diagnostic proof for the README. |