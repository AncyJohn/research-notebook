{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mounting your drive in Colab\" means using a specific command or UI action to link your personal Google Drive cloud storage to the temporary virtual machine (runtime) running your Google Colab notebook. This allows your notebook's code to read from and write to your Drive files as if they were local files in the Colab environment."
      ],
      "metadata": {
        "id": "YioM-Hdvx35D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq-xZzV54Ekc",
        "outputId": "6c7e2b2a-92e6-4d89-ec79-acc946522ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Project already exists in Drive. Moving to folder. ---\n",
            "/content/drive/MyDrive/my_freelance_projects/research-notebook\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (6/6), 816 bytes | 6.00 KiB/s, done.\n",
            "From https://github.com/AncyJohn/research-notebook\n",
            "   1da8153..511bc00  main       -> origin/main\n",
            "Updating 1da8153..511bc00\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\tPhase 3/pipelines/titanic/config.yaml\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n",
            "Repository already exists. Updated with 'git pull'.\n",
            "Current Working Directory: /content/drive/MyDrive/my_freelance_projects/research-notebook\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define your project path and Git URL\n",
        "PROJECT_PATH = '/content/drive/MyDrive/my_freelance_projects'\n",
        "GIT_REPO_URL = 'https://github.com/AncyJohn/research-notebook.git'\n",
        "REPO_NAME = 'research-notebook'\n",
        "FULL_PATH = os.path.join(PROJECT_PATH, REPO_NAME)\n",
        "\n",
        "# 3. Check and Clone/Update\n",
        "if not os.path.exists(FULL_PATH):\n",
        "    # Ensure the parent folder exists\n",
        "    os.makedirs(PROJECT_PATH, exist_ok=True)\n",
        "\n",
        "    # 4. Smart Clone/Access logic\n",
        "    %cd {PROJECT_PATH}\n",
        "    !git clone {GIT_REPO_URL}\n",
        "    print(f\"Successfully cloned into {FULL_PATH}\")\n",
        "else:\n",
        "    # If it exists, just move inside and get latest changes\n",
        "    print(f\"--- Project already exists in Drive. Moving to folder. ---\")\n",
        "    %cd {FULL_PATH}\n",
        "    # Optional: Pull latest changes if you made edits elsewhere\n",
        "    !git pull\n",
        "    print(f\"Repository already exists. Updated with 'git pull'.\")\n",
        "\n",
        "print(f\"Current Working Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to the folder containing your .py files\n",
        "%cd \"Phase 3/pipelines/titanic/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54gK7dXT6awH",
        "outputId": "f7159783-a758-4007-95a6-7969a7d48af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/my_freelance_projects/research-notebook/Phase 3/pipelines/titanic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Train the model\n",
        "!python train.py\n",
        "\n",
        "# Step 2: Evaluate the best saved weights\n",
        "!python evaluate.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsDcs1Z58SPC",
        "outputId": "5f52f64b-977f-40ff-e326-126ae710e94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from: /kaggle/input/titanic/train.csv\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/Phase 3/pipelines/titanic/train.py\", line 247, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/my_freelance_projects/research-notebook/Phase 3/pipelines/titanic/train.py\", line 150, in main\n",
            "    df = pd.read_csv(config['data']['raw_path'])\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "    self.handles = get_handle(\n",
            "                   ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "    handle = open(\n",
            "             ^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/titanic/train.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!find /content -name \"*.pt\"\n",
        "#!find /content -name \"*.joblib\""
      ],
      "metadata": {
        "id": "Zhc0G1XY9X6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current Working Directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hiwwDir_E2C",
        "outputId": "f519cd52-3fd3-4a21-a3d5-6393460e9ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/drive/MyDrive/my_freelance_projects/research-notebook/Phase 3/pipelines/titanic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force writing (since the file looks empty on the drive, usually because the background sync process hasn't finished)\n",
        "import yaml\n",
        "\n",
        "config_content = {\n",
        "    'project_name': \"titanic-baseline\",\n",
        "    'experiment_version': \"v1.1-stable\",\n",
        "    'data': {\n",
        "        'raw_path': \"../../../train.csv\",\n",
        "        'target': \"Survived\",\n",
        "        'drop_columns': ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
        "    },\n",
        "    'train_params': {\n",
        "        'seed': 42,\n",
        "        'test_size': 0.2,\n",
        "        'batch_size': 256,\n",
        "        'lr': 0.001,\n",
        "        'weight_decay': 0.01,\n",
        "        'epochs': 100,\n",
        "        'patience': 10,\n",
        "        'scheduler_factor': 0.5,\n",
        "        'scheduler_patience': 5\n",
        "    },\n",
        "    'model_params': {\n",
        "        'hidden_dim': 16,\n",
        "        'dropout': 0.1\n",
        "    },\n",
        "    'outputs': {\n",
        "        'model_path': \"best_model.pt\",\n",
        "        'stats_path': \"train_stats.joblib\",\n",
        "        'plot_path': \"loss_curve.png\",\n",
        "        'results_path': \"evaluation_metrics.json\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# This forces the file to be created/overwritten in your current directory\n",
        "with open('config.yaml', 'w') as f:\n",
        "    yaml.dump(config_content, f)\n",
        "\n",
        "print(\"âœ… config.yaml has been force-written to:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO9Dq2EcBFaE",
        "outputId": "4b25eb79-eb62-4a44-a635-231c796284c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… config.yaml has been force-written to: /content/drive/MyDrive/my_freelance_projects/research-notebook/Phase 3/pipelines/titanic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIMYu8P6ITrj",
        "outputId": "6f01d506-1282-45c5-c767-3d2349f7e8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from: ../../../train.csv\n",
            "ðŸ’¾ Saving stats to train_stats.joblib...\n",
            "ðŸš€ Starting training on cpu...\n",
            "âœ… Validation loss decreased (None --> 0.7226). Saving model...\n",
            "Epoch 01: Train Loss 0.7253 | Val Loss 0.7226\n",
            "âœ… Validation loss decreased (0.7226043939590454 --> 0.7205). Saving model...\n",
            "Epoch 02: Train Loss 0.7221 | Val Loss 0.7205\n",
            "âœ… Validation loss decreased (0.7205283045768738 --> 0.7181). Saving model...\n",
            "Epoch 03: Train Loss 0.7176 | Val Loss 0.7181\n",
            "âœ… Validation loss decreased (0.7180638909339905 --> 0.7153). Saving model...\n",
            "Epoch 04: Train Loss 0.7136 | Val Loss 0.7153\n",
            "âœ… Validation loss decreased (0.7152968049049377 --> 0.7123). Saving model...\n",
            "Epoch 05: Train Loss 0.7105 | Val Loss 0.7123\n",
            "âœ… Validation loss decreased (0.7122586369514465 --> 0.7091). Saving model...\n",
            "Epoch 06: Train Loss 0.7072 | Val Loss 0.7091\n",
            "âœ… Validation loss decreased (0.7091209292411804 --> 0.7058). Saving model...\n",
            "Epoch 07: Train Loss 0.7041 | Val Loss 0.7058\n",
            "âœ… Validation loss decreased (0.7057745456695557 --> 0.7023). Saving model...\n",
            "Epoch 08: Train Loss 0.7014 | Val Loss 0.7023\n",
            "âœ… Validation loss decreased (0.7023130655288696 --> 0.6988). Saving model...\n",
            "Epoch 09: Train Loss 0.6996 | Val Loss 0.6988\n",
            "âœ… Validation loss decreased (0.6987560391426086 --> 0.6950). Saving model...\n",
            "Epoch 10: Train Loss 0.6934 | Val Loss 0.6950\n",
            "âœ… Validation loss decreased (0.6950360536575317 --> 0.6910). Saving model...\n",
            "Epoch 11: Train Loss 0.6905 | Val Loss 0.6910\n",
            "âœ… Validation loss decreased (0.6909995675086975 --> 0.6868). Saving model...\n",
            "Epoch 12: Train Loss 0.6882 | Val Loss 0.6868\n",
            "âœ… Validation loss decreased (0.6867908239364624 --> 0.6823). Saving model...\n",
            "Epoch 13: Train Loss 0.6825 | Val Loss 0.6823\n",
            "âœ… Validation loss decreased (0.6823051571846008 --> 0.6774). Saving model...\n",
            "Epoch 14: Train Loss 0.6773 | Val Loss 0.6774\n",
            "âœ… Validation loss decreased (0.677436888217926 --> 0.6723). Saving model...\n",
            "Epoch 15: Train Loss 0.6733 | Val Loss 0.6723\n",
            "âœ… Validation loss decreased (0.6722904443740845 --> 0.6661). Saving model...\n",
            "Epoch 16: Train Loss 0.6646 | Val Loss 0.6661\n",
            "âœ… Validation loss decreased (0.6660957336425781 --> 0.6595). Saving model...\n",
            "Epoch 17: Train Loss 0.6623 | Val Loss 0.6595\n",
            "âœ… Validation loss decreased (0.6595185995101929 --> 0.6524). Saving model...\n",
            "Epoch 18: Train Loss 0.6573 | Val Loss 0.6524\n",
            "âœ… Validation loss decreased (0.6524445414543152 --> 0.6450). Saving model...\n",
            "Epoch 19: Train Loss 0.6485 | Val Loss 0.6450\n",
            "âœ… Validation loss decreased (0.6449735164642334 --> 0.6370). Saving model...\n",
            "Epoch 20: Train Loss 0.6418 | Val Loss 0.6370\n",
            "âœ… Validation loss decreased (0.636975109577179 --> 0.6287). Saving model...\n",
            "Epoch 21: Train Loss 0.6344 | Val Loss 0.6287\n",
            "âœ… Validation loss decreased (0.6286793947219849 --> 0.6206). Saving model...\n",
            "Epoch 22: Train Loss 0.6264 | Val Loss 0.6206\n",
            "âœ… Validation loss decreased (0.6205561757087708 --> 0.6125). Saving model...\n",
            "Epoch 23: Train Loss 0.6191 | Val Loss 0.6125\n",
            "âœ… Validation loss decreased (0.6124696135520935 --> 0.6044). Saving model...\n",
            "Epoch 24: Train Loss 0.6080 | Val Loss 0.6044\n",
            "âœ… Validation loss decreased (0.6044099926948547 --> 0.5965). Saving model...\n",
            "Epoch 25: Train Loss 0.6005 | Val Loss 0.5965\n",
            "âœ… Validation loss decreased (0.5965339541435242 --> 0.5888). Saving model...\n",
            "Epoch 26: Train Loss 0.5938 | Val Loss 0.5888\n",
            "âœ… Validation loss decreased (0.5887956023216248 --> 0.5815). Saving model...\n",
            "Epoch 27: Train Loss 0.5844 | Val Loss 0.5815\n",
            "âœ… Validation loss decreased (0.5814724564552307 --> 0.5741). Saving model...\n",
            "Epoch 28: Train Loss 0.5760 | Val Loss 0.5741\n",
            "âœ… Validation loss decreased (0.5741145610809326 --> 0.5669). Saving model...\n",
            "Epoch 29: Train Loss 0.5683 | Val Loss 0.5669\n",
            "âœ… Validation loss decreased (0.5668532848358154 --> 0.5602). Saving model...\n",
            "Epoch 30: Train Loss 0.5630 | Val Loss 0.5602\n",
            "âœ… Validation loss decreased (0.5601675510406494 --> 0.5536). Saving model...\n",
            "Epoch 31: Train Loss 0.5516 | Val Loss 0.5536\n",
            "âœ… Validation loss decreased (0.5536375045776367 --> 0.5473). Saving model...\n",
            "Epoch 32: Train Loss 0.5450 | Val Loss 0.5473\n",
            "âœ… Validation loss decreased (0.5472719669342041 --> 0.5413). Saving model...\n",
            "Epoch 33: Train Loss 0.5370 | Val Loss 0.5413\n",
            "âœ… Validation loss decreased (0.5412824749946594 --> 0.5353). Saving model...\n",
            "Epoch 34: Train Loss 0.5241 | Val Loss 0.5353\n",
            "âœ… Validation loss decreased (0.5353099703788757 --> 0.5296). Saving model...\n",
            "Epoch 35: Train Loss 0.5258 | Val Loss 0.5296\n",
            "âœ… Validation loss decreased (0.5296427607536316 --> 0.5244). Saving model...\n",
            "Epoch 36: Train Loss 0.5180 | Val Loss 0.5244\n",
            "âœ… Validation loss decreased (0.5244424343109131 --> 0.5195). Saving model...\n",
            "Epoch 37: Train Loss 0.5133 | Val Loss 0.5195\n",
            "âœ… Validation loss decreased (0.5194801092147827 --> 0.5147). Saving model...\n",
            "Epoch 38: Train Loss 0.5045 | Val Loss 0.5147\n",
            "âœ… Validation loss decreased (0.5146637558937073 --> 0.5100). Saving model...\n",
            "Epoch 39: Train Loss 0.5003 | Val Loss 0.5100\n",
            "âœ… Validation loss decreased (0.5100240707397461 --> 0.5057). Saving model...\n",
            "Epoch 40: Train Loss 0.4929 | Val Loss 0.5057\n",
            "âœ… Validation loss decreased (0.5056872367858887 --> 0.5014). Saving model...\n",
            "Epoch 41: Train Loss 0.4934 | Val Loss 0.5014\n",
            "âœ… Validation loss decreased (0.5014155507087708 --> 0.4974). Saving model...\n",
            "Epoch 42: Train Loss 0.4851 | Val Loss 0.4974\n",
            "âœ… Validation loss decreased (0.4973752200603485 --> 0.4936). Saving model...\n",
            "Epoch 43: Train Loss 0.4804 | Val Loss 0.4936\n",
            "âœ… Validation loss decreased (0.49357300996780396 --> 0.4900). Saving model...\n",
            "Epoch 44: Train Loss 0.4791 | Val Loss 0.4900\n",
            "âœ… Validation loss decreased (0.4899868965148926 --> 0.4865). Saving model...\n",
            "Epoch 45: Train Loss 0.4712 | Val Loss 0.4865\n",
            "âœ… Validation loss decreased (0.4865105450153351 --> 0.4832). Saving model...\n",
            "Epoch 46: Train Loss 0.4681 | Val Loss 0.4832\n",
            "âœ… Validation loss decreased (0.4832362234592438 --> 0.4801). Saving model...\n",
            "Epoch 47: Train Loss 0.4652 | Val Loss 0.4801\n",
            "âœ… Validation loss decreased (0.4800814688205719 --> 0.4770). Saving model...\n",
            "Epoch 48: Train Loss 0.4596 | Val Loss 0.4770\n",
            "âœ… Validation loss decreased (0.4770281910896301 --> 0.4743). Saving model...\n",
            "Epoch 49: Train Loss 0.4601 | Val Loss 0.4743\n",
            "âœ… Validation loss decreased (0.4742802381515503 --> 0.4717). Saving model...\n",
            "Epoch 50: Train Loss 0.4541 | Val Loss 0.4717\n",
            "âœ… Validation loss decreased (0.4717056155204773 --> 0.4692). Saving model...\n",
            "Epoch 51: Train Loss 0.4496 | Val Loss 0.4692\n",
            "âœ… Validation loss decreased (0.46923622488975525 --> 0.4668). Saving model...\n",
            "Epoch 52: Train Loss 0.4496 | Val Loss 0.4668\n",
            "âœ… Validation loss decreased (0.46684712171554565 --> 0.4646). Saving model...\n",
            "Epoch 53: Train Loss 0.4473 | Val Loss 0.4646\n",
            "âœ… Validation loss decreased (0.4646308422088623 --> 0.4626). Saving model...\n",
            "Epoch 54: Train Loss 0.4515 | Val Loss 0.4626\n",
            "âœ… Validation loss decreased (0.4626106023788452 --> 0.4610). Saving model...\n",
            "Epoch 55: Train Loss 0.4504 | Val Loss 0.4610\n",
            "âœ… Validation loss decreased (0.4609861671924591 --> 0.4592). Saving model...\n",
            "Epoch 56: Train Loss 0.4406 | Val Loss 0.4592\n",
            "âœ… Validation loss decreased (0.45917633175849915 --> 0.4574). Saving model...\n",
            "Epoch 57: Train Loss 0.4465 | Val Loss 0.4574\n",
            "âœ… Validation loss decreased (0.45736294984817505 --> 0.4557). Saving model...\n",
            "Epoch 58: Train Loss 0.4394 | Val Loss 0.4557\n",
            "âœ… Validation loss decreased (0.45571890473365784 --> 0.4541). Saving model...\n",
            "Epoch 59: Train Loss 0.4403 | Val Loss 0.4541\n",
            "âœ… Validation loss decreased (0.4541400074958801 --> 0.4527). Saving model...\n",
            "Epoch 60: Train Loss 0.4359 | Val Loss 0.4527\n",
            "âœ… Validation loss decreased (0.4526616930961609 --> 0.4511). Saving model...\n",
            "Epoch 61: Train Loss 0.4350 | Val Loss 0.4511\n",
            "âœ… Validation loss decreased (0.4511049687862396 --> 0.4500). Saving model...\n",
            "Epoch 62: Train Loss 0.4356 | Val Loss 0.4500\n",
            "âœ… Validation loss decreased (0.44997474551200867 --> 0.4488). Saving model...\n",
            "Epoch 63: Train Loss 0.4325 | Val Loss 0.4488\n",
            "âœ… Validation loss decreased (0.44882717728614807 --> 0.4477). Saving model...\n",
            "Epoch 64: Train Loss 0.4311 | Val Loss 0.4477\n",
            "âœ… Validation loss decreased (0.44768938422203064 --> 0.4468). Saving model...\n",
            "Epoch 65: Train Loss 0.4259 | Val Loss 0.4468\n",
            "âœ… Validation loss decreased (0.4468030035495758 --> 0.4460). Saving model...\n",
            "Epoch 66: Train Loss 0.4249 | Val Loss 0.4460\n",
            "âœ… Validation loss decreased (0.44598662853240967 --> 0.4452). Saving model...\n",
            "Epoch 67: Train Loss 0.4319 | Val Loss 0.4452\n",
            "âœ… Validation loss decreased (0.4452035427093506 --> 0.4445). Saving model...\n",
            "Epoch 68: Train Loss 0.4170 | Val Loss 0.4445\n",
            "âœ… Validation loss decreased (0.44449228048324585 --> 0.4442). Saving model...\n",
            "Epoch 69: Train Loss 0.4295 | Val Loss 0.4442\n",
            "âœ… Validation loss decreased (0.4441523551940918 --> 0.4436). Saving model...\n",
            "Epoch 70: Train Loss 0.4261 | Val Loss 0.4436\n",
            "âœ… Validation loss decreased (0.4435885548591614 --> 0.4432). Saving model...\n",
            "Epoch 71: Train Loss 0.4245 | Val Loss 0.4432\n",
            "âœ… Validation loss decreased (0.44317737221717834 --> 0.4424). Saving model...\n",
            "Epoch 72: Train Loss 0.4369 | Val Loss 0.4424\n",
            "âœ… Validation loss decreased (0.4424148499965668 --> 0.4417). Saving model...\n",
            "Epoch 73: Train Loss 0.4186 | Val Loss 0.4417\n",
            "âœ… Validation loss decreased (0.4416728615760803 --> 0.4412). Saving model...\n",
            "Epoch 74: Train Loss 0.4155 | Val Loss 0.4412\n",
            "âœ… Validation loss decreased (0.44122281670570374 --> 0.4409). Saving model...\n",
            "Epoch 75: Train Loss 0.4173 | Val Loss 0.4409\n",
            "âœ… Validation loss decreased (0.44091400504112244 --> 0.4407). Saving model...\n",
            "Epoch 76: Train Loss 0.4112 | Val Loss 0.4407\n",
            "âœ… Validation loss decreased (0.4407009482383728 --> 0.4407). Saving model...\n",
            "Epoch 77: Train Loss 0.4141 | Val Loss 0.4407\n",
            "âœ… Validation loss decreased (0.4406850337982178 --> 0.4404). Saving model...\n",
            "Epoch 78: Train Loss 0.4214 | Val Loss 0.4404\n",
            "âœ… Validation loss decreased (0.4404086172580719 --> 0.4400). Saving model...\n",
            "Epoch 79: Train Loss 0.4162 | Val Loss 0.4400\n",
            "âœ… Validation loss decreased (0.4399715065956116 --> 0.4397). Saving model...\n",
            "Epoch 80: Train Loss 0.4255 | Val Loss 0.4397\n",
            "âœ… Validation loss decreased (0.4396818280220032 --> 0.4392). Saving model...\n",
            "Epoch 81: Train Loss 0.4128 | Val Loss 0.4392\n",
            "âœ… Validation loss decreased (0.4392227530479431 --> 0.4392). Saving model...\n",
            "Epoch 82: Train Loss 0.4148 | Val Loss 0.4392\n",
            "âœ… Validation loss decreased (0.4392032325267792 --> 0.4392). Saving model...\n",
            "Epoch 83: Train Loss 0.4138 | Val Loss 0.4392\n",
            "âš ï¸ No improvement. EarlyStopping counter: 1/10\n",
            "Epoch 84: Train Loss 0.4195 | Val Loss 0.4392\n",
            "âš ï¸ No improvement. EarlyStopping counter: 2/10\n",
            "Epoch 85: Train Loss 0.4166 | Val Loss 0.4394\n",
            "âš ï¸ No improvement. EarlyStopping counter: 3/10\n",
            "Epoch 86: Train Loss 0.4082 | Val Loss 0.4392\n",
            "âš ï¸ No improvement. EarlyStopping counter: 4/10\n",
            "Epoch 87: Train Loss 0.4057 | Val Loss 0.4393\n",
            "âœ… Validation loss decreased (0.43917182087898254 --> 0.4390). Saving model...\n",
            "Epoch 88: Train Loss 0.4158 | Val Loss 0.4390\n",
            "âš ï¸ No improvement. EarlyStopping counter: 1/10\n",
            "Epoch 89: Train Loss 0.4213 | Val Loss 0.4390\n",
            "âœ… Validation loss decreased (0.43903055787086487 --> 0.4389). Saving model...\n",
            "Epoch 90: Train Loss 0.4200 | Val Loss 0.4389\n",
            "âœ… Validation loss decreased (0.4389294683933258 --> 0.4388). Saving model...\n",
            "Epoch 91: Train Loss 0.3994 | Val Loss 0.4388\n",
            "âœ… Validation loss decreased (0.4387955963611603 --> 0.4387). Saving model...\n",
            "Epoch 92: Train Loss 0.4159 | Val Loss 0.4387\n",
            "âš ï¸ No improvement. EarlyStopping counter: 1/10\n",
            "Epoch 93: Train Loss 0.4157 | Val Loss 0.4389\n",
            "âš ï¸ No improvement. EarlyStopping counter: 2/10\n",
            "Epoch 94: Train Loss 0.4146 | Val Loss 0.4394\n",
            "âš ï¸ No improvement. EarlyStopping counter: 3/10\n",
            "Epoch 95: Train Loss 0.4089 | Val Loss 0.4398\n",
            "âš ï¸ No improvement. EarlyStopping counter: 4/10\n",
            "Epoch 96: Train Loss 0.4126 | Val Loss 0.4401\n",
            "âš ï¸ No improvement. EarlyStopping counter: 5/10\n",
            "Epoch 97: Train Loss 0.4177 | Val Loss 0.4399\n",
            "âš ï¸ No improvement. EarlyStopping counter: 6/10\n",
            "Epoch 98: Train Loss 0.4061 | Val Loss 0.4398\n",
            "âš ï¸ No improvement. EarlyStopping counter: 7/10\n",
            "Epoch 99: Train Loss 0.4114 | Val Loss 0.4397\n",
            "âš ï¸ No improvement. EarlyStopping counter: 8/10\n",
            "Epoch 100: Train Loss 0.4097 | Val Loss 0.4395\n",
            "ðŸ“Š Plot saved to loss_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the file content\n",
        "!cat evaluate.py"
      ],
      "metadata": {
        "id": "9rmNsU9SInoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# force writing evaluate.py\n",
        "%%writefile evaluate.py\n",
        "import torch\n",
        "import yaml\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# Reusing classes from train.py\n",
        "from train import PreprocessingDataset, BaselineNet\n",
        "\n",
        "def evaluate():\n",
        "    config_path = \"config.yaml\"\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = yaml.safe_load(f)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    df = pd.read_csv(config['data']['raw_path'])\n",
        "\n",
        "    _, val_df = train_test_split(\n",
        "        df,\n",
        "        test_size=config['train_params']['test_size'],\n",
        "        stratify=df[config['data']['target']],\n",
        "        random_state=config['train_params']['seed']\n",
        "    )\n",
        "\n",
        "    # 2. Load Artifacts\n",
        "    stats = joblib.load(config['outputs']['stats_path'])\n",
        "    val_ds = PreprocessingDataset(val_df, config['data']['target'], config['data']['drop_columns'], stats=stats)\n",
        "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=config['train_params']['batch_size'], shuffle=False)\n",
        "\n",
        "    # 3. Load Model\n",
        "    input_size = val_ds.X.shape[1]\n",
        "    model = BaselineNet(input_size, config['model_params']['hidden_dim'], config['model_params']['dropout']).to(device)\n",
        "    model.load_state_dict(torch.load(config['outputs']['model_path'], weights_only=True, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    # 4. Inference\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            outputs = torch.sigmoid(model(x.to(device))).view(-1)\n",
        "            all_preds.extend((outputs > 0.5).cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "\n",
        "    # 5. Output Results\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"STABLE BASELINE EVALUATION\")\n",
        "    print(\"=\"*30)\n",
        "    print(f\"Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZVk1gOkXHWE",
        "outputId": "5f6cf85e-7278-478a-83c6-c209e070acd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vcxUs7RZL8y",
        "outputId": "b4999305-0903-4a7f-8b47-b2cf009aac8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "STABLE BASELINE EVALUATION\n",
            "==============================\n",
            "Accuracy: 0.8045\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.90      0.85       110\n",
            "         1.0       0.80      0.65      0.72        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.80      0.78      0.78       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99ouNyCGZW94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}