{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75120,
     "status": "ok",
     "timestamp": 1770118884199,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "yz8dYY2fAJp0",
    "outputId": "c3921d69-5a11-4fa3-cc00-ebd3c2b55edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "--- Project already exists in Drive. Moving to folder. ---\n",
      "/content/drive/MyDrive/my_freelance_projects/research-notebook\n",
      "Already up to date.\n",
      "Repository already exists. Updated with 'git pull'.\n",
      "Current Working Directory: /content/drive/MyDrive/my_freelance_projects/research-notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Mount your drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define your project path and Git URL\n",
    "PROJECT_PATH = '/content/drive/MyDrive/my_freelance_projects'\n",
    "GIT_REPO_URL = 'https://github.com/AncyJohn/research-notebook.git'\n",
    "REPO_NAME = 'research-notebook'\n",
    "FULL_PATH = os.path.join(PROJECT_PATH, REPO_NAME)\n",
    "\n",
    "# 3. Check and Clone/Update\n",
    "if not os.path.exists(FULL_PATH):\n",
    "    # Ensure the parent folder exists\n",
    "    os.makedirs(PROJECT_PATH, exist_ok=True)\n",
    "\n",
    "    # 4. Smart Clone/Access logic\n",
    "    %cd {PROJECT_PATH}\n",
    "    !git clone {GIT_REPO_URL}\n",
    "    print(f\"Successfully cloned into {FULL_PATH}\")\n",
    "else:\n",
    "    # If it exists, just move inside and get latest changes\n",
    "    print(f\"--- Project already exists in Drive. Moving to folder. ---\")\n",
    "    %cd {FULL_PATH}\n",
    "    # Optional: Pull latest changes if you made edits elsewhere\n",
    "    !git pull\n",
    "    print(f\"Repository already exists. Updated with 'git pull'.\")\n",
    "\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4579,
     "status": "ok",
     "timestamp": 1770119369474,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "phljP6_LDIJf",
    "outputId": "8fc5c923-e03d-490a-e469-abae2e096f05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9SMpbjzyIry"
   },
   "source": [
    "CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA that allows developers to use a GPU for general-purpose processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ge-Jpf2uCGm"
   },
   "source": [
    "Open the Specific Notebook.\n",
    "You must open the notebook file to execute its cells.\n",
    "In the left sidebar of Colab, click the Folder icon.\n",
    "Navigate to: my_freelance_projects → research-notebook → phase2 → deep_learning → tabular.\n",
    "Double-click 01_pytorch_baseline.ipynb. This will open the file in a new tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS-DbuNV0l6r"
   },
   "source": [
    "Set the Working Directory (Inside the New Tab)\n",
    "Colab notebooks always start in '/content' by default, regardless of where the file is stored. In the first cell of your newly opened 01_pytorch_baseline.ipynb, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUwniBPk1RwH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount drive if not already connected in this session\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Change directory to where THIS notebook is located\n",
    "# This allows the code to use relative paths like '../../kaggle/data.csv'\n",
    "#%cd /content/drive/MyDrive/my_freelance_projects/research-notebook/phase2/deep_learning/tabular/\n",
    "%cd /content/drive/MyDrive/my_freelance_projects/research-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTHny15aGeQM"
   },
   "source": [
    "To access the data source from Kaggle, generate a token file from my kaggle account settings page. I used the 'Create Legacy API Key' button. This action automatically downloaded a file named kaggle.json to your local machine. Place it in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 12290,
     "status": "ok",
     "timestamp": 1770119539461,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "1Rf3zrVlGRt_",
    "outputId": "bcdff3f1-63ce-4562-c84e-01ab292c90b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ff62ab4b-167a-4b87-963c-aa68d591be38\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ff62ab4b-167a-4b87-963c-aa68d591be38\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"ancyjohn\",\"key\":\"4d2f0970f090251bb11dc160015cb9e9\"}'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the file\n",
    "from google.colab import files\n",
    "files.upload() # Select the 'kaggle.json' file you downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1770119617590,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "cJiNdNypUR2M"
   },
   "outputs": [],
   "source": [
    "# Move it to the secret loacation\n",
    "!mkdir -p ~/.kaggle # Create the hidden directory\n",
    "!cp kaggle.json ~/.kaggle/ # Move the file there\n",
    "!chmod 600 ~/.kaggle/kaggle.json #Set permissions (required by Kaggle for security)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wBWhzBnTlrP"
   },
   "source": [
    "Default API Path: The Kaggle API tool is hardcoded to look for credentials in ~/.kaggle/ (which translates to /root/.kaggle/ in Colab).\n",
    "Security: Running chmod 600 ensures that only the owner can read the file, which prevents the Kaggle tool from throwing a \"permissions are too wide\" warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1770119709475,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "CrQ4zPr-TrFC",
    "outputId": "87bf2c89-fcd7-4c2a-ae18-b0cdd8c5f4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                  title                                                size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------  ---------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
      "heptapod/titanic                     Titanic                                             11090  2017-05-16 08:14:22.210000         143886       1859  0.7058824        \n",
      "brendan45774/test-file               Titanic dataset                                     11514  2021-12-02 16:11:42.367000         219291       1715  1.0              \n",
      "yasserh/titanic-dataset              Titanic Dataset                                     22564  2021-12-24 14:53:06.913000         271408        832  1.0              \n",
      "azeembootwala/titanic                Titanic                                             12406  2017-06-05 12:14:37.477000          26137        209  0.8235294        \n",
      "rahulsah06/titanic                   Titanic                                             34877  2019-09-16 14:43:23.910000          13759        141  0.6764706        \n",
      "sakshisatre/titanic-dataset          Titanic Dataset                                     60609  2024-04-30 19:20:37.987000           7721         81  1.0              \n",
      "shubhamgupta012/titanic-dataset      Titanic Dataset                                      6833  2023-06-18 07:52:20.030000           7583         61  1.0              \n",
      "waqi786/titanic-dataset              Titanic Dataset                                     41548  2024-07-25 08:23:03.090000           3894         41  1.0              \n",
      "ibrahimelsayed182/titanic-dataset    Titanic dataset                                      5731  2022-01-27 07:41:54.683000           5871         39  1.0              \n",
      "fossouodonald/titaniccsv             Titanic csv                                          1030  2016-11-07 09:44:58.073000          22024        165  0.5882353        \n",
      "zain280/titanic-data-set             Titanic Data set                                    22544  2024-02-28 14:04:13.953000           5047         73  1.0              \n",
      "prkukunoor/TitanicDataset            Titanic                                            138274  2017-01-03 22:01:13.023000           6168         37  0.5882353        \n",
      "hesh97/titanicdataset-traincsv       Titanic-Dataset (train.csv)                         22544  2018-02-02 04:51:06.950000         114989        584  0.4117647        \n",
      "pavlofesenko/titanic-extended        Titanic extended dataset (Kaggle + Wikipedia)      137471  2019-03-06 09:53:24.747000          15880        174  0.9411765        \n",
      "jamesleslie/titanic-cleaned-data     Titanic: cleaned data                               36367  2018-11-21 11:50:18.683000          10290         73  0.7647059        \n",
      "mahmoudshogaa/titanic-dataset        titanic_dataset                                     22491  2023-11-24 14:19:44.907000           3099         65  1.0              \n",
      "ashishkumarjayswal/titanic-datasets  Titanic Survival Datasets                           11516  2022-05-25 04:23:42.153000           6882         65  0.7647059        \n",
      "broaniki/titanic                     titanic                                            733956  2018-01-30 04:08:45.227000           9137        132  0.1764706        \n",
      "kittisaks/testtitanic                test titanic                                        22558  2017-03-13 15:13:12.767000           2394         38  0.64705884       \n",
      "lovishbansal123/titanic-dataset      Titanic Dataset                                     22564  2024-02-16 13:53:32.563000            722         39  1.0              \n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "!kaggle datasets list -s \"titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1770119720929,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "Tc66UwalU8Kg",
    "outputId": "e9021384-0849-4664-c35f-5ea5158a106c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to /content/drive/MyDrive/my_freelance_projects/research-notebook\n",
      "\r  0% 0.00/34.1k [00:00<?, ?B/s]\n",
      "\r100% 34.1k/34.1k [00:00<00:00, 4.68MB/s]\n",
      "Archive:  titanic.zip\n",
      "  inflating: gender_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "!kaggle competitions download -c titanic\n",
    "!unzip -o titanic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1770119741228,
     "user": {
      "displayName": "Ancy John",
      "userId": "03103432617251529434"
     },
     "user_tz": -780
    },
    "id": "xdPUr07HVVl7",
    "outputId": "f7e8084f-2242-41f7-e237-3f7434924036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gender_submission.csv\t'Phase 1'   README.md   titanic.zip\n",
      " kaggle.json\t\t'Phase 2'   test.csv    train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKZAPRHiY-g9"
   },
   "source": [
    "Now you can run the notebook tab for 01_pytorch_baseline.ipynb, by simply running pd.read_csv(\"train.csv\") if the CSV is in the root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "My work today was portable. My model ran outside Kaggle, on cloud compute. It didn't depend on my local system. It didn't brake."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPMiEc5Uty+4Z2keyOWydKP",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
