{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c273a6f3-4ebf-40fa-b33a-75c81eaabda2",
   "metadata": {},
   "source": [
    "# Validation & Experimental Discipline\n",
    "\n",
    "## Research Question\n",
    "Why do we need validation data in addition to test data?\n",
    "\n",
    "## Hypothesis\n",
    "Using validation data helps prevent overfitting to the test set and leads to better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf7914e-f6a8-42e7-b193-61bca4f2eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185a614b-5168-4b69-9076-df411bc167b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "rng = np.random.default_rng(seed=43)\n",
    "X = rng.random((150, 1)) * 5\n",
    "y = X.squeeze()**2 + rng.standard_normal(150) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c2875-fd7e-46fc-a6c5-10a1d7b95c65",
   "metadata": {},
   "source": [
    "### Note\n",
    "Modern NumPy Generator API (`default_rng`) used for reproducibility and isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8471348-c642-411a-be2b-575009e51496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=43\n",
    ") # This separates 20% of the total data to be used as the Test Set (X_test, y_test). \n",
    "#You are left with 80% of the data in \"temporary\" variables (X_temp, y_temp) to be split again in the next step.\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=43\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819ca7b-93eb-4b8a-b5a2-991df9333936",
   "metadata": {},
   "source": [
    "### Why Three Sets?\n",
    "- Training: learn parameters 60%\n",
    "- Validation: tune model complexity 20%\n",
    "- Test: final unbiased evaluation 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ffde980-beff-4a55-b105-37fe4d8f605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 14.65957569526338, 2: 8.208992679407546, 5: 9.219451784576465}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune model using validation set\n",
    "# Try three model complexities and compare the validation error\n",
    "degrees = [1, 2, 5]\n",
    "results = {}\n",
    "\n",
    "for d in degrees:\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_train_p = poly.fit_transform(X_train)\n",
    "    X_val_p = poly.transform(X_val)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_p, y_train)\n",
    "\n",
    "    val_mse = mean_squared_error(y_val, model.predict(X_val_p))\n",
    "    results[d] = val_mse\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b25a0-a6a4-44fa-84f6-b307dd60821e",
   "metadata": {},
   "source": [
    "### Validation Results\n",
    "- Degree with lowest validation error is selected\n",
    "- Test set remains untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2981d18-a03a-4036-9f0d-389fefb1a7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.092860577694728"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final evaluation on Test set\n",
    "best_degree = min(results, key=results.get)\n",
    "\n",
    "poly = PolynomialFeatures(degree=best_degree)\n",
    "X_train_p = poly.fit_transform(X_train)\n",
    "X_test_p = poly.transform(X_test)\n",
    "\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_p, y_train)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, final_model.predict(X_test_p))\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06c89b-d1a2-44a0-8f2f-191db77663e3",
   "metadata": {},
   "source": [
    "### Final Test Performance\n",
    "- Test set used only once\n",
    "- Provides unbiased performance estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75311b2-ccf8-4a42-93cb-2ae46c27690c",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- Validation data prevents overfitting decisions\n",
    "- Test data should be touched once\n",
    "- Experimental discipline is as important as model choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128c459-4892-445d-af36-ee0727f665e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
