{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be5fef-0b5f-4a24-8b1b-f29a0ed26f14",
   "metadata": {},
   "source": [
    "Models are not magic.\n",
    "They are hypotheses tested on data.\n",
    "Writing hypotheses and reflections made the experiment feel purposeful rather than mechanical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c0fa6-ec6b-4781-b673-27055de65f4d",
   "metadata": {},
   "source": [
    "# Non-Linear Data Experiment\n",
    "\n",
    "## Research Question\n",
    "Can linear regression model non-linear data?\n",
    "\n",
    "## Hypothesis\n",
    "A linear regression model will perform poorly on non-linear data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b92ba9-9760-49a2-b85b-e2d5859eda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d74176-8765-4ff7-bba9-5085951ec26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "X = rng.random((200, 1)) * 5\n",
    "y = X.squeeze()**2 + rng.standard_normal(200) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fe7fc-7702-465c-8705-2a6a497cf549",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- y is proportional to x² (quadratic relationship)\n",
    "- Added noise to simulate real-world data\n",
    "- Expect linear model to struggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7a8fa1-ed8a-49db-be90-1326edc88882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b8c972-f19b-4015-a680-43f6157cf167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.292388869218822"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear model\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lin = lin_model.predict(X_test)\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "\n",
    "mse_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae02b65-e8e6-49a0-96cf-144e5c677acd",
   "metadata": {},
   "source": [
    "### Linear Model Result\n",
    "- High MSE indicates poor fit\n",
    "- Linear model cannot capture curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831858dd-039b-48c7-bc91-8806b6827177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce non-linearity (Polinomial features)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c0e1a-469b-4723-b407-2edb08b45890",
   "metadata": {},
   "source": [
    "This code performs feature engineering to transform linear input data into polynomial terms. This allows a standard linear regression model to capture non-linear (curved) relationships in your data. \n",
    "\n",
    "poly = PolynomialFeatures(degree=2)This initializes the transformer. A degree=2 setting means it will generate all combinations of features up to the power of 2.\n",
    "Example: If your input is a single feature ([a]), it generates ([1,a,a^{2}]).\n",
    "Example: If your input has two features \\([a,b]\\), it generates \\([1,a,b,a^{2},ab,b^{2}]\\).\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)This performs two actions on your training data in one step:\n",
    "fit: The transformer \"learns\" the number of input features and the required output structure.\n",
    "transform: It actually creates the new polynomial columns (like squared terms and interactions) and returns the expanded feature matrix.\n",
    "\n",
    "X_test_poly = poly.transform(X_test)This applies the exact same transformation to your test data.\n",
    "Crucial Note: You only use transform() here (not fit_transform) to ensure the test data is handled using the parameters learned from the training set. This prevents \"data leakage\" and ensures your model is tested on features structured exactly like those it was trained on. \n",
    "\n",
    "Why use this? Linear models can only draw straight lines. By adding \\(X^{2}\\) as a new feature, you effectively turn a \"Linear Regression\" model into a \"Polynomial Regression\" model, allowing it to fit curves and capture more complex patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b11b92-a0f1-4f43-a4e8-79612e352388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.129033932418055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "mse_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ff1f1-451f-4c70-9a22-04d9ee3aff49",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "- Linear MSE: 8.2924\n",
    "- Polynomial MSE: 4.129\n",
    "\n",
    "### Interpretation\n",
    "- Adding non-linearity significantly reduced error\n",
    "- Model complexity matters when data is non-linear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9af40-9574-4889-bc4d-c74bcbecc5e5",
   "metadata": {},
   "source": [
    "This is exactly what neural networks do:\n",
    "\n",
    "Polynomial features = manual non-linearity\n",
    "\n",
    "Neural networks = learned non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88df01a-3b4c-46e1-b78f-46dc1ad12b6f",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- Linear models fail on non-linear relationships\n",
    "- Introducing non-linearity dramatically improves performance\n",
    "- This motivates neural networks and deep learning\n",
    "- Model power must match data complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd484d-ecb7-4a8a-b52c-50b318f490a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
